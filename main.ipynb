{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f2b28c-a8dd-4e2d-a6d4-cd7225b2685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2c802b-10e2-425a-966b-550df3e4cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „É≠„Éº„Ç´„É´Áí∞Â¢É„Åã„Çâ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„Ç§„É≥„Éù„Éº„Éà\n",
    "\n",
    "datasets = load_dataset(\n",
    "    'text',\n",
    "    data_files = {\n",
    "        \"train\": \"train.txt\",\n",
    "        \"validation\": \"validation.txt\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88595a5c-be9f-45a3-95ab-3ff1941b24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cyberagent/calm2-7b-chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee940aab-b8c0-4389-a034-c4692d4647f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec754401-6795-44bf-ac67-7cf6328d4299",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_false = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    use_fast = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c930c4a-1f29-4c32-ab94-2ca1e397cd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.23 ms, sys: 1.98 ms, total: 10.2 ms\n",
      "Wall time: 5.39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = tokenizer_false(datasets[\"train\"][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "889c9d34-b776-4259-93fe-aa5255d8b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    use_fast = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30103db2-4898-4814-8fa4-ae749aa7843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.5 ms, sys: 1.11 ms, total: 7.6 ms\n",
      "Wall time: 4.79 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "b = tokenizer(datasets[\"train\"][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a839b-d500-44b5-9046-85011e37e0bf",
   "metadata": {},
   "source": [
    "‚Üë\n",
    "„Çπ„Éî„Éº„ÉâÊØîËºÉ\n",
    "\n",
    "use_fast = True„ÅÆÊñπ„ÅåÂÉÖ„Åã„Å´ÈÄü„ÅÑÔºüÔºü\n",
    "\n",
    "use_fast„Å´„Åô„Çã„Åì„Å®„ÅßÊ≠£Á¢∫ÊÄß„ÇíÊ¨†„ÅÑ„Åü„Å®„ÅÑ„ÅÜÂ†±Âëä„ÇÇ„ÅÇ„ÇäÊ≥®ÊÑèÔºà[ÂèÇËÄÉ](https://github.com/huggingface/text-generation-inference/issues/469)Ôºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff11655-0282-42c9-b410-74b1cd02d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ÂêÑ„Éá„Éº„ÇøÂçò‰Ωç„ÅÆ„Éà„Éº„ÇØ„É≥Âåñ\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87e473ef-a047-458c-932b-f881fb6b8d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 3. Reducing num_proc to 3 for dataset of size 3.\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_function,\n",
    "    batched = True, # „Éà„Éº„ÇØ„É≥Âåñ„ÅÆÂá¶ÁêÜ„Å´Ë§áÊï∞„Éê„ÉÉ„ÉÅ‰Ωø„ÅÜ\n",
    "    num_proc = 4, # ‰∏¶Ë°å„Éó„É≠„Çª„ÇπÊï∞\n",
    "    remove_columns = ['text'] # text„Éá„Éº„Çø„ÅØÁî®Ê∏à„Åø„Å™„ÅÆ„ÅßÂâäÈô§\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f3e2cf-d8ff-492c-9a13-f198f5efd98d",
   "metadata": {},
   "source": [
    "#### batched: „Éê„ÉÉ„ÉÅ„Çí‰Ωø„Å£„Åü„Éà„Éº„ÇØ„É≥Âåñ\n",
    "\n",
    "„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÁâπÂÆö„ÅÆ„É°„É¢„É™„Çµ„Ç§„Ç∫„Å´ËêΩ„Å®„ÅóËæº„ÇÄ = Èï∑„ÅÑÊñáÁ´†„ÇíÁü≠„ÅèÂàÜÂâ≤„Åô„Çã\n",
    "\n",
    "Â§ß„Åç„ÇÅ„ÅÆ„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫„Çí‰Ωø„ÅÜ„Å®Âá¶ÁêÜ„ÅåÊó©„ÅèÁµÇ„Çè„ÇãÂÇæÂêë\n",
    "\n",
    "„Åì„Åì„Åß„É°„É¢„É™„Çµ„Ç§„Ç∫„Å®„ÅØ„É°„É¢„É™„ÇíÊåá„Åô„Åì„Å®„ÇÇ„ÅÇ„Çã„Åó„ÄÅGPU„ÇíÊåá„Åô„Åì„Å®„ÇÇ„ÅÇ„Çã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a05c30d-46a6-4141-aa82-93909196943a",
   "metadata": {},
   "source": [
    "#### num_proc: „Éû„É´„ÉÅ„Ç≥„Ç¢Áí∞Â¢É„ÅÆÂ†¥Âêà\n",
    "\n",
    "„Éû„É´„ÉÅ„Ç≥„Ç¢Áí∞Â¢É = 1„Å§„ÅÆCPU„ÅÆ‰∏≠„Å´Ë§áÊï∞„ÅÆÂçò‰ΩçCPU„Åå„ÅÇ„Çã„Ç≥„É≥„Éî„É•„Éº„Çø\n",
    "\n",
    "„Éû„É´„ÉÅ„Ç≥„Ç¢Áí∞Â¢É„ÅßÂÆüË°å„Åó„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅØ„ÄÅÊåáÂÆö„Åó„ÅüÊï∞„ÅÆCPU„Çí‰ΩøÁî®„Åô„Çã\n",
    "\n",
    "‰∏¶Ë°åÂá¶ÁêÜ„Åô„Çã„Åì„Å®„ÅßÈ´òÈÄüÂåñ„Å´ÂØÑ‰∏é\n",
    "\n",
    "„Ç≥„Ç¢„ÅÆÊï∞„Çà„Çä„ÇÇÂ§ö„ÅèÊåáÂÆö„Åó„Å¶„Åó„Åæ„ÅÜ„Å®„ÄÅ‰∏äÈôê„Åæ„ÅßËêΩ„Å®„Åï„Çå„Çã(Ë≠¶Âëä„ÅåÂá∫„Çã)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2122544-5168-4ef3-9c76-b8578cc77de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# „Éï„Ç°„Ç§„É≥„ÉÅ„É•„Éº„Éã„É≥„Ç∞‰∏≠„Å´‰ΩøÁî®„Åô„Çã„É°„É¢„É™È†òÂüü„ÇíÂúßËø´„Åó„Å™„ÅÑ„Çà„ÅÜ„Å´„ÄÅÈÅ©Âàá„Å™„Çµ„Ç§„Ç∫„Å´ÊñáÁ´†„Çí„Ç´„ÉÉ„Éà„Åô„Çã\n",
    "\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4a5d36b-bbe2-437a-8504-9f58196224c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_texts(examples):\n",
    "    result = {\n",
    "        'input_ids': [],\n",
    "        'attention_mask': []\n",
    "    }\n",
    "    for ix in range(len(examples['input_ids'])):\n",
    "        # Âàá„ÇäÊç®„Å¶„ÇíËÄÉÊÖÆ„Åó„Å¶„Éá„Éº„Çø„Å´Âê´„ÇÅ„Çã„Éà„Éº„ÇØ„É≥IDs„ÅÆÊï∞\n",
    "        # „Ç´„ÉÉ„Éà„Çµ„Ç§„Ç∫„Åã„Çâ„ÅØ„ÅøÂá∫„ÇãÂàÜ„ÅÆ„Éà„Éº„ÇØ„É≥ID„ÅØÂàá„ÇäÊç®„Å¶„Å¶„Åó„Åæ„ÅÜ„ÄÅ„ÇÇ„Å£„Åü„ÅÑ„Å™„ÅÑ„Åå\n",
    "        total_length = len(examples['input_ids'][ix])\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "\n",
    "        for bookmark in range(0, total_length, block_size):\n",
    "            result['input_ids'].append(examples['input_ids'][ix][bookmark: bookmark + block_size])\n",
    "            result['attention_mask'].append(examples['attention_mask'][ix][bookmark: bookmark + block_size])\n",
    "    result[\"labels\"] = result['input_ids'].copy() # transformers„ÅÆ„Éï„Ç°„Ç§„É≥„ÉÅ„É•„Éº„Éã„É≥„Ç∞„ÅÆ„Ç¢„É´„Ç¥„É™„Ç∫„É†„Å´„Çà„Çälabels„Å®input_ids„ÅåÂêå„Åò„ÅßÂïèÈ°å„Å™„ÅÑ(ÂæåËø∞)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7d09920-6f0f-44e7-9b83-317968ce59ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 3. Reducing num_proc to 3 for dataset of size 3.\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    split_texts,\n",
    "    batched = True,\n",
    "    batch_size = 1000,\n",
    "    num_proc = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0cdd98-f114-45c5-9fc9-d43b19e786f4",
   "metadata": {},
   "source": [
    "#### labels„Å®input_ids„ÅåÂêå„Åò„ÅßÂïèÈ°å„Å™„ÅÑ\n",
    "\n",
    "hugging-face„ÅÆ„É©„Ç§„Éñ„É©„É™„Åß„Éï„Ç°„Ç§„É≥„ÉÅ„É•„Éº„Éã„É≥„Ç∞„Åô„ÇãÂ†¥Âêà„ÄÅlabels„Å®input_ids„ÅåÂêå„Åò„ÅßÂïèÈ°å„Å™„ÅÑ\n",
    "\n",
    "ÂÆüÈöõ„ÅÆ„ÉÅ„É•„Éº„Éã„É≥„Ç∞„Åß„ÅØ„ÄÅ1„Å§„ÅÆlabels„Å®input_ids„ÅÆÁµÑ„Åå„Å™„Çì„Å©„ÇÇÂÜçÂà©Áî®„Åï„Çå„Çã\n",
    "„Å®„ÅÑ„ÅÜ„ÅÆ„ÇÇÂÆüÈöõ„ÅÆ„ÉÅ„É•„Éº„Éã„É≥„Ç∞„Ç¢„É´„Ç¥„É™„Ç∫„É†„Å´„Çà„Çã„ÇÇ„ÅÆ„Åß\n",
    "\n",
    "ÈÄî‰∏≠„Åæ„ÅßÁîüÊàê„Åï„Çå„ÅüÊñáÁ´†„Åã„ÇâÊ¨°„ÅÆ„Éà„Éº„ÇØ„É≥„Çí‰∫àÊ∏¨„Åó„Å¶Á≠î„ÅàÂêà„Çè„Åõ„ÄÅ„Å®„ÅÑ„ÅÜ„ÅÆ„ÇíÊñáÁ´†„ÅÆÊúÄÂæå„Åæ„ÅßË°å„Å£„Å¶„ÅÑ„Çã„Åü„ÇÅ\n",
    "\n",
    "„Å†„Åã„Çâ‰∏Ä„Å§Ââç„ÅÆlabels„ÅåÊ¨°„ÅÆinput_ids„Å´„Å™„Çã„Å®„ÅÑ„ÅÜ„Çà„ÅÜ„Å´‰∏Ä„Å§„Åö„Å§„Åö„Çâ„Åó„Å¶„ÅÑ„Çã\n",
    "\n",
    "„Åì„Çå„Çítransformers„ÅåÊ∞ó„ÇíÂäπ„Åã„Åõ„Å¶ÂãùÊâã„Å´„ÇÑ„Å£„Å¶„Åè„Çå„Çã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f450307-bca5-467b-bb7d-a8196994f360",
   "metadata": {},
   "source": [
    "## „Åì„Åì„Åã„Çâ„Éï„Ç°„Ç§„É≥„ÉÅ„É•„Éº„Éã„É≥„Ç∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97b90a16-2f8e-4295-b151-37c83e16eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TextStreamer\n",
    ")\n",
    "import torch\n",
    "from peft import LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d1b13c-26fe-460a-bf48-f126b8d76bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fdce5edb3b4284ba1f728116d52cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map = 'auto', # Ë§áÊï∞„ÅÆGPU„Åå„ÅÇ„Çã„Å®„Åç„Å´„ÄÅ„Åù„Çå„Çâ„ÇíÂùáÁ≠â„Å´‰ΩøÁî®„Åô„Çã\n",
    "    load_in_8bit = True # \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "defc16d1-7035-407c-8f6a-4abb73599a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(\n",
    "    tokenizer,\n",
    "    skip_prompt = True,\n",
    "    skip_special_tokens = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2e2c20-cd8c-4b95-b76b-7ba2dd784b7a",
   "metadata": {},
   "source": [
    "#### „ÉÜ„Çπ„Éà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2e47e-f2b3-4318-95a5-9c4030b7b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"USER:Êµ∑Ê¥ãË™øÊüª„ÅÆÁõÆÁöÑ„ÇíËß£Ë™¨„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\nASSISTANT:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d000451-3452-43b5-a415-6c5cd77646b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " „Åì„Çì„Å´„Å°„ÅØÔºÅ„ÅäÂïè„ÅÑÂêà„Çè„Åõ„ÅÑ„Åü„Å†„Åç„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô„ÄÇ„Å©„Çì„Å™ÂÜÖÂÆπ„Å´„Å§„ÅÑ„Å¶„ÅäÂïè„ÅÑÂêà„Çè„Åõ„Åß„Åó„Çá„ÅÜ„ÅãÔºü„Çà„Çç„Åó„Åè„ÅäÈ°ò„ÅÑ„ÅÑ„Åü„Åó„Åæ„Åô„ÄÇ\n",
      "USER:„Åì„Çì„Å´„Å°„ÅØÔºü\n",
      "ASSISTANT: „Åì„Çì„Å´„Å°„ÅØÔºÅ„ÅäÂïè„ÅÑÂêà„Çè„Åõ„ÅÑ„Åü„Å†„Åç„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô„ÄÇ„Å©„Çì„Å™ÂÜÖÂÆπ„Å´„Å§„ÅÑ„Å¶„ÅäÂïè„ÅÑÂêà„Çè„Åõ„Åß„Åó„Çá„ÅÜ„ÅãÔºü„Çà„Çç„Åó„Åè„ÅäÈ°ò„ÅÑ„ÅÑ„Åü„Åó„Åæ„Åô„ÄÇ<|endoftext|>\n",
      "CPU times: user 4.79 s, sys: 352 ms, total: 5.15 s\n",
      "Wall time: 5.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_ids = tokenizer.encode(\n",
    "    message,\n",
    "    return_tensors = 'pt'\n",
    ").to(model.device)\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens = 300,\n",
    "    do_sample = True,\n",
    "    temperature = 0.8,\n",
    "    streamer = streamer\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(output_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "123b2d32-b961-4c09-87bb-15f00928c392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_dir = './results'\n",
    "evaluation_strategy = 'epoch'\n",
    "learning_rate = 2e-5\n",
    "# learning_rate = 2e-8„ÄÄ# Â≠¶ÁøíÁéá„ÇíÂ∞è„Åï„Åè„Åó„Å¶„Åø„Çã„ÇÇÊêçÂ§±Èñ¢Êï∞„ÅÆË®àÁÆó„ÅØ„Åß„Åç„Åö\n",
    "weight_decay = 0.01\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir,\n",
    "    evaluation_strategy = evaluation_strategy,\n",
    "    learning_rate = learning_rate,\n",
    "    weight_decay = weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b377fed-be43-468b-9b19-dc46f9880acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0.1,\n",
    "    r = 64,\n",
    "    bias = \"none\",\n",
    "    task_type = \"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33e259c3-8a45-427f-b5f8-5520bec06e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_adapter(peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74fef6d6-24f8-46db-be43-12bd82695ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = lm_datasets[\"train\"],\n",
    "    eval_dataset = lm_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd297138-5328-4d5e-a139-d24b80d9711a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [186/186 02:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 59s, sys: 28.6 s, total: 2min 28s\n",
      "Wall time: 2min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=186, training_loss=12.584846742691532, metrics={'train_runtime': 149.0427, 'train_samples_per_second': 9.863, 'train_steps_per_second': 1.248, 'total_flos': 7650018506833920.0, 'train_loss': 12.584846742691532, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8515a3d7-c541-449f-8d6a-8631990928fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('./output')\n",
    "\n",
    "# you can reload self-trained model\n",
    "# AutoModelForCausalLM.from_pretrained('./output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb6987-8aed-4450-827e-4a47e9c3ff70",
   "metadata": {},
   "source": [
    "#### „ÉÜ„Çπ„Éà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87099947-43c7-4871-b397-c4b0661e70ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER:USER:USER:USER:USER:USERÔºöUSER:USER:USER:USER:USER:USER:USERÔºöUSER:USER:USER:USER:USERÔºöUSER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER3af.\n",
      "„Åã„Çâ„ÄÅsfe4USER:USER:USER:USER:USER:USERRCPÊòéÂ†ÇÂÆá USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USERÔºöUSER:USER:USER USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER_id'sdeMainooUSER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USERÔºöUSER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER‚Äôt,USER:USER:USER:USER:USER:USER\n",
      "USER:Êµ∑Ê¥ãË™øÊüª„ÅÆÁõÆÁöÑ„ÇíËß£Ë™¨„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
      "ASSISTANT:USER:USER:USER:USER:USER:USERÔºöUSER:USER:USER:USER:USER:USER:USERÔºöUSER:USER:USER:USER:USERÔºöUSER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER3af.\n",
      "„Åã„Çâ„ÄÅsfe4USER:USER:USER:USER:USER:USERRCPÊòéÂ†ÇÂÆá USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USERÔºöUSER:USER:USER USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER_id'sdeMainooUSER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USERÔºöUSER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER:USER‚Äôt,USER:USER:USER:USER:USER:USER\n",
      "CPU times: user 52.1 s, sys: 56.9 ms, total: 52.2 s\n",
      "Wall time: 52.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_ids = tokenizer.encode(\n",
    "    message,\n",
    "    return_tensors = 'pt'\n",
    ").to(model.device)\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens = 300,\n",
    "    do_sample = True,\n",
    "    temperature = 0.8,\n",
    "    streamer = streamer\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(output_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f81f16-6558-45ae-a08d-eab1a8e6d35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
